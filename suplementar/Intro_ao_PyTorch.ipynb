{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Diferenciação do PyTorch\n",
        "\n",
        "import torch\n",
        "x = torch.ones(1, 1, requires_grad=True)\n",
        "print(f\"x = {x}\")\n",
        "print(f\"x.data = {x.data}\")\n",
        "print(f\"x.grad = {x.grad}\")\n",
        "print(f\"x.grad_fn = {x.grad_fn}\")"
      ],
      "metadata": {
        "id": "5Ra1y_OBkYvQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x + 2\n",
        "print(f\"y = {y}\")\n",
        "print(f\"y.grad_fn = {y.grad_fn}\")"
      ],
      "metadata": {
        "id": "ZcLSmHjEmy5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "z = y * y * 3\n",
        "print(z)"
      ],
      "metadata": {
        "id": "LbEfwREBnH1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "z.backward()\n",
        "print(x.grad)"
      ],
      "metadata": {
        "id": "pEcjhUmBnP6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  !pip install torchmetrics\n",
        "# https://torchmetrics.readthedocs.io/en/latest/\n",
        "\n",
        "import torch\n",
        "import torch.nn\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X, y = torch.Tensor(X), torch.Tensor(y)\n",
        "\n",
        "y = torch.where(y == 0, 0, 1).type(torch.float32)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X, y, test_size=0.33, random_state=42)\n",
        "\n",
        "\n",
        "def standard_scaler(X):\n",
        "  std, mean = torch.std_mean(X)\n",
        "  return lambda S: (S - mean) / std\n",
        "\n",
        "scaler = standard_scaler(X_train)\n",
        "X_train, X_test = scaler(X_train), scaler(X_test)\n"
      ],
      "metadata": {
        "id": "HXLjw_dhSSHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Construir o modelo;\n",
        "2. Definir o otimizador;\n",
        "3. Treinar com *loop* das épocas;"
      ],
      "metadata": {
        "id": "WxDDCevLQR68"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uB6ylnYLPROA"
      },
      "outputs": [],
      "source": [
        "# construção do modelo\n",
        "import torch.nn as nn\n",
        "\n",
        "# mlp com duas camadas, a oculta com 10 neurônios\n",
        "# a de saída com 1 neurônio\n",
        "\n",
        "mlp = nn.Sequential(\n",
        "    nn.Linear(4, 10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10, 1),\n",
        "    nn.Flatten(),\n",
        "    nn.ReLU(),\n",
        ")\n",
        "\n",
        "print(mlp)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta é uma lista de alguns otimizadores comuns:\n",
        "- ```torch.optim.Adam()```: O algoritmo de Adam (estimativa do momento adaptativo);\n",
        "- ```torch.optim.NAdam()```: O algoritmo de Adam com momento de Nesterov;\n",
        "- ```torch.optim.SGD()```: Descida de gradiente estocástico;\n",
        "- ```torch.optim.RMSprop()```: O algoritmo RMSprop."
      ],
      "metadata": {
        "id": "2FtnrD30R3Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir o otimizador\n",
        "otimizador = torch.optim.Adam(mlp.parameters(), lr=0.001)\n",
        "otimizador"
      ],
      "metadata": {
        "id": "C1WimNllQgRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Abaixo estão algumas funções de perda comuns no PyTorch:\n",
        " - ```nn.MSELoss()```: erro quadrático médio, útil em problemas de regressão;\n",
        " - ```nn.CrossEntropyLoss()```: perda de entropia cruzada, útil em problemas de classificação multi-classe;\n",
        " - ```nn.BCELoss()```: perda de entropia cruzada binária, útil em problemas de classificação binária."
      ],
      "metadata": {
        "id": "TyYqQwDoQ77s"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gRVDwOPpTa6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loop de treinamento\n",
        "epocas = 50\n",
        "funcao_custo = nn.BCELoss()\n",
        "\n",
        "# gradiente descendente em lote cheio\n",
        "for n in range(epocas):\n",
        "  y_pred = mlp(X_train)\n",
        "  custo = funcao_custo(y_pred.squeeze(), y_train)\n",
        "  otimizador.zero_grad()\n",
        "  custo.backward()\n",
        "  otimizador.step()\n",
        "\n",
        "# rede treinada!\n",
        "\n"
      ],
      "metadata": {
        "id": "Ku7-eDnsPxKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = mlp(X_test).squeeze()\n",
        "custo_teste = funcao_custo(y_pred, y_test)\n",
        "\n",
        "print(f\"Último custo de treino: {custo}\")\n",
        "\n",
        "print(f\"Custo de teste {custo_teste}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IooEhSvdGtue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics import Accuracy\n",
        "\n",
        "accuracy = Accuracy(task=\"binary\")\n",
        "accuracy(y_pred, y_test)"
      ],
      "metadata": {
        "id": "Am7B6hKrLbw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "f\"Nossa mlp possui {count_parameters(mlp)} parâmetros treináveis.\"\n"
      ],
      "metadata": {
        "id": "F3XxszcaGwQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preceptron\n",
        "class Perceptron(torch.nn.Module):\n",
        "    def __init__(self, input_size, epochs=400, lr=0.001):\n",
        "        super().__init__()\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr\n",
        "        self.fc = nn.Linear(input_size, 1)\n",
        "        self.relu = torch.nn.Sigmoid() # instead of Heaviside step fn\n",
        "\n",
        "    def count_parameters(self):\n",
        "      return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.fc(x)\n",
        "        output = self.relu(output) # instead of Heaviside step fn\n",
        "        return output\n",
        "\n",
        "    def fit(self, X, y):\n",
        "      funcao_custo = nn.BCELoss()\n",
        "\n",
        "      otimizador = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "\n",
        "      # gradiente descendente em lote cheio\n",
        "      for n in range(self.epochs):\n",
        "        otimizador.zero_grad()\n",
        "\n",
        "        y_pred = self.predict(X)\n",
        "\n",
        "        custo = funcao_custo(y_pred, y)\n",
        "\n",
        "        custo.backward()\n",
        "        otimizador.step()\n",
        "\n",
        "    def predict(self, X):\n",
        "      return self.forward(X).squeeze()\n",
        "\n",
        "    def score(self, X, y):\n",
        "      from torchmetrics import Accuracy\n",
        "\n",
        "      accuracy = Accuracy(task=\"binary\")\n",
        "      return accuracy(self.predict(X), y)\n",
        "\n",
        "\n",
        "p = Perceptron(4)\n",
        "p.fit(X_train, y_train)\n",
        "print(f\"Acuracia: {p.score(X_test, y_test)}\")\n",
        "print(f\"N params {p.count_parameters()}\")\n",
        "\n",
        "# https://colab.research.google.com/github/bentrevett/pytorch-image-classification/blob/master/1_mlp.ipynb#scrollTo=lAqzcW9XREvu"
      ],
      "metadata": {
        "id": "w9MAsL4EIczI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qrxF3gUnPfmF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}